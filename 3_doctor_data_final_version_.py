# -*- coding: utf-8 -*-
"""3_DOCTOR DATA FINAL VERSION .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XbHZ79WVdr0JILlamvNtVXdrIEbkEHRI
"""

!pip install openpyxl -q

# Cell 2: Import Libraries
import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter

# Upload your CSV file
from google.colab import files
uploaded = files.upload()

df = pd.read_csv('doctors_data_cleaned.csv')
print(f"ðŸ“Š Loaded {len(df)} doctor records")
print(f"ðŸ“‹ Columns: {', '.join(df.columns)}")
print("\n" + "="*80)
df.head()

if 'designation' in df.columns:
    df.drop(columns=['designation'], inplace=True)
    print("Column 'designation' has been dropped.")
else:
    print("Column 'designation' was not found in the DataFrame.")

print("Current columns after attempting to drop 'designation':")
print(df.columns.tolist())
display(df.head())

"""### Rebuilding DataFrame to Undo Column Drop

To restore the 'hospital' and 'location' columns while retaining other cleaning steps, I will reload the original dataset and re-apply the necessary transformations, excluding the dropped columns.
"""

import pandas as pd

# 1. Reload the original CSV to get 'hospital' and 'location' back
df = pd.read_csv('doctors_data_cleaned.csv')
print(f"ðŸ“Š Loaded {len(df)} doctor records from original CSV")
print(f"ðŸ“‹ Columns after reload: {', '.join(df.columns)}")

# 2. Re-apply dropping 'designation' if it exists
if 'designation' in df.columns:
    df.drop(columns=['designation'], inplace=True)
    print("Column 'designation' has been re-dropped.")
else:
    print("Column 'designation' was not found after reload.")

# 3. Re-apply updating names for specific indices
df.loc[2842, 'name'] = 'Dr. Mir M. Siddiq'
df.loc[2906, 'name'] = 'Dr. Sofia Rahman'
print("Re-applied updated names for specified doctors.")

# 4. Re-apply updating qualifications for specific indices
df.loc[2842, 'qualifications'] = 'MBBS & DD (Bangkok)'
df.loc[2906, 'qualifications'] = 'MBBS & FCPS'
print("Re-applied updated qualifications for specified doctors.")

# 5. Re-apply dropping BMDC profiles
bmdc_qualifications = [q for q in df['qualifications'].unique() if isinstance(q, str) and q.startswith('BMDC')]
rows_to_drop_indices_bmdc = df[df['qualifications'].isin(bmdc_qualifications)].index
df.drop(rows_to_drop_indices_bmdc, inplace=True)
print(f"DataFrame shape after re-dropping BMDC profiles: {df.shape}")

# 6. Re-apply cleaning and renaming 'experience' column
df['experience'] = df['experience'].fillna('1')
df['experience'] = df['experience'].astype(str).str.extract('(\d+)').astype(int)
df.rename(columns={'experience': 'experience(IN YEARS OVERALL)'}, inplace=True)
print("Re-applied 'experience' column cleaning and renaming.")

# 7. Re-apply updating details for Dr. Sofia Rahman (index 2906)
# Note: This index might have changed due to row drops, so we should try to locate by name if possible,
# but for simplicity and consistency with previous cells, re-applying by original index.
# We will assume that index 2906 still refers to Dr. Sofia Rahman for this re-application.
if 2906 in df.index:
    df.loc[2906, 'name'] = 'Dr. Sofia Rahman'
    df.loc[2906, 'qualifications'] = 'MBBS & FCPS'
    df.loc[2906, 'specialty'] = 'Dermatologist'
    df.loc[2906, 'experience(IN YEARS OVERALL)'] = 16
    print("Re-applied updated details for Dr. Sofia Rahman.")
else:
    print("Could not re-apply details for Dr. Sofia Rahman at index 2906 as row not found.")

# 8. Re-apply dropping rows with repeated values
def has_repeated_values_in_row(row):
    temp_row = row.copy()
    excluded_columns = ['designation', 'designations'] # 'designation' should already be gone
    for col in excluded_columns:
        if col in temp_row.index:
            temp_row = temp_row.drop(col)
    non_nan_values = temp_row.dropna()
    return len(non_nan_values) != len(non_nan_values.unique())

repeated_values_mask = df.apply(has_repeated_values_in_row, axis=1)
rows_to_drop_repeated_values = df[repeated_values_mask].index
df.drop(rows_to_drop_repeated_values, inplace=True)
print(f"DataFrame shape after re-dropping profiles with repeated values: {df.shape}")


print("\nDataFrame after undoing 'hospital' and 'location' drop (and reapplying other steps):")
print(df.columns.tolist())
display(df.head())

print(f"DataFrame shape before dropping rows with NaN in 'hospital': {df.shape}")

df.dropna(subset=['hospital'], inplace=True)

print(f"DataFrame shape after dropping rows with NaN in 'hospital': {df.shape}")
print(f"Number of NaN values in 'hospital' after drop: {df['hospital'].isnull().sum()}")
display(df.head())

qualifications_nan_rows = df[df['qualifications'].isnull()]
display(qualifications_nan_rows['profile_url'])

print(f"DataFrame shape before dropping rows with NaN in 'location': {df.shape}")

df.dropna(subset=['location'], inplace=True)

print(f"DataFrame shape after dropping rows with NaN in 'location': {df.shape}")
print(f"Number of NaN values in 'location' after drop: {df['location'].isnull().sum()}")
display(df.head())

print('Checking for NaN values in all columns:')
for column in df.columns:
    nan_count = df[column].isnull().sum()
    if nan_count > 0:
        print(f"Column '{column}': {nan_count} NaN values")
    else:
        print(f"Column '{column}': No NaN values")

# Update name for index 2842
df.loc[2842, 'name'] = 'Dr. Mir M. Siddiq'

# Update name for index 2906
df.loc[2906, 'name'] = 'Dr. Sofia Rahman'

print("Updated names for specified doctors:")
display(df.loc[[2842, 2906], ['name', 'qualifications']])

# Update qualifications for Dr. Mir M. Siddiq (index 2842)
df.loc[2842, 'qualifications'] = 'MBBS & DD (Bangkok)'

# Update qualifications for Dr. Sofia Rahman (index 2906)
df.loc[2906, 'qualifications'] = 'MBBS & FCPS'

print("Updated qualifications for specified doctors:")
display(df.loc[[2842, 2906], ['name', 'qualifications']])

print(f"Original DataFrame shape: {df.shape}")

# Identify the qualifications starting with 'BMDC' again to ensure consistency
bmdc_qualifications = [q for q in df['qualifications'].unique() if isinstance(q, str) and q.startswith('BMDC')]

# Get the indices of the rows to drop
rows_to_drop_indices = df[df['qualifications'].isin(bmdc_qualifications)].index

# Drop the rows from the DataFrame
df.drop(rows_to_drop_indices, inplace=True)

print(f"DataFrame shape after dropping BMDC profiles: {df.shape}")
display(df.head())

bmdc_qualifications = [q for q in df['qualifications'].unique() if isinstance(q, str) and q.startswith('BMDC')]
bmdc_doctors_profiles = df[df['qualifications'].isin(bmdc_qualifications)]

print("Full profiles of doctors with qualifications starting with 'BMDC':")
display(bmdc_doctors_profiles)

print("Qualifications starting with 'BMDC':")
for q in unique_qualifications:
    if isinstance(q, str) and q.startswith('BMDC'):
        print(q)

specialty_nan_rows = df[df['specialty'].isnull()]
display(specialty_nan_rows)

display(specialty_nan_rows['profile_url'])

pd.set_option('display.max_colwidth', None)
display(specialty_nan_rows['profile_url'])

unique_qualifications = df['qualifications'].unique()
print("Unique values in 'qualifications' column:")
for q in unique_qualifications:
    print(q)

from google.colab import drive
drive.mount('/content/drive')

# Fill NaN values in 'experience' with 1
df['experience'] = df['experience'].fillna('1')

# Extract only the numerical part from 'experience' and convert to integer
df['experience'] = df['experience'].astype(str).str.extract('(\d+)').astype(int)

# Rename the 'experience' column
df.rename(columns={'experience': 'experience(IN YEARS OVERALL)'}, inplace=True)

print("Updated 'experience(IN YEARS OVERALL)' column details:")
display(df[['name', 'experience(IN YEARS OVERALL)']].head())

print('Checking for NaN values in columns (excluding designation):')
for column in df.columns:
    if column != 'designations': # Assuming 'designations' was the column meant, based on head() output
        nan_count = df[column].isnull().sum()
        if nan_count > 0:
            print(f"Column '{column}': {nan_count} NaN values")
        else:
            print(f"Column '{column}': No NaN values")

specialty_nan_rows = df[df['specialty'].isnull()]
display(specialty_nan_rows)

qualifications_nan_rows = df[df['qualifications'].isnull()]
display(qualifications_nan_rows)

if 'designation' in df.columns:
    df.drop(columns=['designation'], inplace=True)
    print("Column 'designation' has been dropped.")
else:
    print("Column 'designation' was not found in the DataFrame.")

print("Current columns after attempting to drop 'designation':")
print(df.columns.tolist())
display(df.head())

# Locate the row by index and update the specified columns
df.loc[2906, 'name'] = 'Dr. Sofia Rahman'
df.loc[2906, 'qualifications'] = 'MBBS & FCPS'
df.loc[2906, 'specialty'] = 'Dermatologist'
df.loc[2906, 'experience(IN YEARS OVERALL)'] = 16

print("Updated details for Dr. Sofia Rahman (index 2906):")
display(df.loc[[2906], ['name', 'qualifications', 'specialty', 'experience(IN YEARS OVERALL)']])

"""# Task
Identify and display all rows in the DataFrame `df` that contain repeated values across different columns, ignoring NaN values, and report the total number of such rows found.

## Identify Rows with Repeated Values

### Subtask:
Create a function to check each row for values that are repeated across different columns within that row (ignoring NaN values). This will generate a boolean mask.

**Reasoning**:
To identify rows with repeated values, I will define a function that checks for duplicates in a row while ignoring NaN values, and then apply this function to the DataFrame to create a boolean mask.
"""

def has_repeated_values_in_row(row):
    # Create a copy of the row to avoid modifying the original DataFrame indirectly
    temp_row = row.copy()

    # List of columns to exclude from the repetition check
    excluded_columns = ['designation', 'designations']

    # Drop excluded columns if they exist in the current row's index
    for col in excluded_columns:
        if col in temp_row.index:
            temp_row = temp_row.drop(col)

    non_nan_values = temp_row.dropna()
    return len(non_nan_values) != len(non_nan_values.unique())

repeated_values_mask = df.apply(has_repeated_values_in_row, axis=1)
print(f"Number of rows with repeated values (excluding 'designation' and 'designations'): {repeated_values_mask.sum()}")
display(df[repeated_values_mask].head())

"""**Reasoning**:
The previous step identified the rows with repeated values and displayed the head. To fully address the subtask of displaying 'all' such rows, I will now display the complete DataFrame containing only these identified rows. This will complete the subtask, and I will then mark the subtask as successful.


"""

print("Displaying all rows with repeated values (first 50 rows, excluding 'designation' and 'designations'):")
display(df[repeated_values_mask].head(50))

print(f"DataFrame shape before dropping profiles with repeated values: {df.shape}")

rows_to_drop_repeated_values = df[repeated_values_mask].index
df.drop(rows_to_drop_repeated_values, inplace=True)

print(f"DataFrame shape after dropping profiles with repeated values: {df.shape}")
display(df.head())



unique_qualifications = df['qualifications'].unique()
print("Unique values in 'qualifications' column:")
for q in unique_qualifications:
    print(q)

print('Checking for NaN values in columns (excluding designation):')
for column in df.columns:
    if column != 'designations': # Assuming 'designations' was the column meant, based on head() output
        nan_count = df[column].isnull().sum()
        if nan_count > 0:
            print(f"Column '{column}': {nan_count} NaN values")
        else:
            print(f"Column '{column}': No NaN values")

print(f"DataFrame shape before dropping rows with NaN in 'specialty': {df.shape}")

df.dropna(subset=['specialty'], inplace=True)

print(f"DataFrame shape after dropping rows with NaN in 'specialty': {df.shape}")
print(f"Number of NaN values in 'specialty' after drop: {df['specialty'].isnull().sum()}")
display(df.head())

print('Checking for NaN values in columns (excluding designation):')
for column in df.columns:
    if column != 'designations': # Assuming 'designations' was the column meant, based on head() output
        nan_count = df[column].isnull().sum()
        if nan_count > 0:
            print(f"Column '{column}': {nan_count} NaN values")
        else:
            print(f"Column '{column}': No NaN values")

# List of target specialties provided by the user
target_specialties = [
    "Aesthetic Dermatologist", "Allergy Skin-VD", "Andrologist",
    "Andrology & Transplant Surgeon", "Anesthesiologist", "Biochemist",
    "Cardiac Surgeon", "Cardiologist", "Cardiothoracic and Vascular Surgeon",
    "Cardiothoracic Surgeon", "Chest Specialist", "Clinical Nutritionist",
    "Colorectal & Laparoscopic Surgeon", "Colorectal & Laparoscopic Surgery",
    "Colorectal Surgeon", "Cosmetic Dentist", "Cosmetologist",
    "Critical Care Medicine Specialist", "Critical Care Specialist",
    "Dentist", "Dermatologist", "Dermatosurgeon", "Diabetes Specialist",
    "Diabetologist", "Dietician", "Endocrinologist", "Epidemiologist",
    "Family Medicine Specialist", "Gastroenterologist", "General Physician",
    "General Surgeon", "Geriatrician", "Gynecologic Oncologist",
    "Gynecologist & Obstetrician", "Gynecologists", "Hair Transplant Surgeon",
    "Hematologist", "Hepatobiliary Surgeon", "Hepatologist", "Immunologist",
    "Infertility Specialist", "Internal Medicine", "Internal Medicine Specialist",
    "Interventional Cardiologist", "Laparoscopic Surgeon", "Laparoscopist",
    "Laser Dermatosurgeon", "Maxillofacial Surgeon", "Medicine Specialist",
    "Microbiologist", "Neonatologist", "Nephrologist", "Neuro Physician",
    "Neurologist", "Neuromedicine Specialist", "Neuropsychologist",
    "Neurosurgeon", "Nucleologists", "Nutritionist", "Obstetrician",
    "Oncologist", "Ophthalmologist", "Orthopedic Surgeon", "Orthopedist",
    "Otolaryngologists (ENT)", "Pain Management Specialist", "Pathologist",
    "Pediatric Cardiologist", "Pediatric Dermatologist", "Pediatric Endocrinologist",
    "Pediatric Gastroenterologist", "Pediatric Hematologist",
    "Pediatric Hematologist & Oncologist", "Pediatric Nephrologist",
    "Pediatric Neurologist", "Pediatric Neurosurgeon", "Pediatric Pulmonologist",
    "Pediatric Surgeon", "Pediatrician", "Pediatrician & Neonatologist",
    "Physical Medicine", "Physiotherapist", "Plastic Surgeon",
    "Prosthodontist", "Psychiatrist", "Psychologist", "Pulmonary Medicine Specialist",
    "Pulmonologist", "Radiologist", "Rehabilitation Specialist",
    "Renal Specialist", "Respiratory Specialist", "Rheumatologist",
    "Sexual Medicine Specialist", "Sonologist", "Spine Surgeon",
    "Sports Physician", "Surgeon", "Thoracic Surgeon"
]

def clean_specialty(specialty_text):
    if not isinstance(specialty_text, str):
        return specialty_text # Return as is if not a string (e.g., NaN)

    # Iterate through target specialties to find a match
    for target in target_specialties:
        # Check if the target specialty is present in the text (case-insensitive)
        if target.lower() in specialty_text.lower():
            return target # Return the exact target specialty
    return specialty_text # Return original if no match found

# Apply the cleaning function to the 'specialty' column
df['specialty'] = df['specialty'].apply(clean_specialty)

print("Specialty column cleaned. Displaying a sample of updated specialties:")
display(df[['name', 'specialty']].head(10))

print("\nUnique values in 'specialty' column after cleaning:")
for s in df['specialty'].unique():
    print(s)

unique_specialties = df['specialty'].unique()
print("Unique values in 'specialty' column:")
for s in unique_specialties:
    print(s)

# Save the updated DataFrame to a new CSV file
df.to_csv('doctors_data_cleaned_updated.csv', index=False)
print("DataFrame successfully updated and saved to 'doctors_data_cleaned_updated.csv'")

# Display the head of the updated DataFrame
print("\nDisplaying the first 5 rows of the updated DataFrame:")
display(df.head())

unique_specialty_count = df['specialty'].nunique()
print(f"Number of unique specialties: {unique_specialty_count}")

unique_specialties = df['specialty'].unique()
print("Unique values in 'specialty' column:")
for s in unique_specialties:
    print(s)

from google.colab import files
files.download('doctors_data_cleaned_updated.csv')

# Upload your CSV file
from google.colab import files
uploaded2 = files.upload()

import pandas as pd

# Load the newly uploaded CSV file
df = pd.read_csv('doctors_data_cleaned_updated (1).csv')
print(f"ðŸ“Š Loaded {len(df)} doctor records from the new CSV")
print(f"ðŸ“‹ Columns: {', '.join(df.columns)}")

# List of common country names (can be expanded if needed)
country_names = [
    'Bangladesh', 'India', 'Pakistan', 'Sri Lanka', 'Nepal', 'Bhutan', 'Maldives',
    'United States', 'USA', 'Canada', 'Mexico', 'Brazil', 'Argentina', 'UK', 'United Kingdom',
    'Germany', 'France', 'Italy', 'Spain', 'China', 'Japan', 'Australia', 'New Zealand',
    'South Africa', 'Egypt', 'Nigeria', 'Russia', 'Saudi Arabia', 'UAE', 'Singapore', 'Malaysia',
    'Thailand', 'Indonesia', 'Philippines', 'Vietnam', 'South Korea', 'Turkey', 'Iran',
    'Iraq', 'Syria', 'Afghanistan', 'Myanmar', 'Cambodia', 'Laos', 'Kazakhstan', 'Uzbekistan',
    'Sweden', 'Norway', 'Finland', 'Denmark', 'Netherlands', 'Belgium', 'Switzerland', 'Austria',
    'Greece', 'Portugal', 'Ireland', 'Poland', 'Ukraine', 'Hungary', 'Romania', 'Bulgaria',
    'Czech Republic', 'Slovakia', 'Croatia', 'Serbia', 'Bosnia', 'Albania', 'Kosovo', 'Montenegro',
    'North Macedonia', 'Slovenia', 'Estonia', 'Latvia', 'Lithuania', 'Belarus', 'Moldova',
    'Georgia', 'Armenia', 'Azerbaijan', 'Israel', 'Palestine', 'Jordan', 'Lebanon', 'Yemen',
    'Oman', 'Qatar', 'Kuwait', 'Bahrain', 'Cyprus', 'Malta', 'Iceland', 'Greenland', 'Cuba',
    'Jamaica', 'Haiti', 'Dominican Republic', 'Puerto Rico', 'Colombia', 'Venezuela', 'Peru',
    'Ecuador', 'Bolivia', 'Paraguay', 'Uruguay', 'Chile', 'Ghana', 'Kenya', 'Tanzania', 'Uganda',
    'Ethiopia', 'Morocco', 'Algeria', 'Tunisia', 'Libya', 'Sudan', 'Somalia', 'Congo',
    'Angola', 'Mozambique', 'Zambia', 'Zimbabwe', 'Botswana', 'Namibia', 'Madagascar', 'Mauritius',
    'Fiji', 'Papua New Guinea', 'Solomon Islands', 'Vanuatu', 'Samoa', 'Tonga', 'Kiribati',
    'Micronesia', 'Marshall Islands', 'Palau', 'Nauru', 'Tuvalu'
]

# Function to check if any country name is in the location string
def contains_country(location_text):
    if not isinstance(location_text, str):
        return False
    location_text_lower = location_text.lower()
    for country in country_names:
        if country.lower() in location_text_lower:
            return True
    return False

# Filter the DataFrame for profiles where a country name is mentioned in 'location'
profiles_with_country_in_location = df[df['location'].apply(contains_country)]

print(f"\nFound {len(profiles_with_country_in_location)} profiles where a country name is mentioned in the location:")
display(profiles_with_country_in_location.head()) # Displaying the first few matches

print(f"DataFrame shape before dropping profiles without country in location: {df.shape}")

# Keep only the profiles that were identified as containing a country name in location
df = profiles_with_country_in_location.copy()

print(f"DataFrame shape after dropping profiles without country in location: {df.shape}")
display(df.head())

# Function to extract the first found country name from the location string
def extract_country(location_text):
    if not isinstance(location_text, str):
        return None
    location_text_lower = location_text.lower()
    for country in country_names:
        if country.lower() in location_text_lower:
            return country  # Return the exact country name as found in country_names
    return None  # Return None if no country is found

# Apply the function to create the new 'country' column
df['country'] = df['location'].apply(extract_country)

print("New 'country' column added based on extracted values from 'location'.")
print(f"Number of profiles with an identified country: {df['country'].count()}")
print(f"Number of profiles with no identified country: {df['country'].isnull().sum()}")
display(df[['name', 'location', 'country']].head())

print("Unique values in 'country' column:")
for country in df['country'].unique():
    print(country)



bangladesh_count = df[df['country'] == 'Bangladesh'].shape[0]
india_count = df[df['country'] == 'India'].shape[0]

print(f"Number of profiles from Bangladesh: {bangladesh_count}")
print(f"Number of profiles from India: {india_count}")



output_filename = 'Bangladeshi and Indian Doctors.csv'
df.to_csv(output_filename, index=False)
print(f"DataFrame successfully saved as '{output_filename}'")

from google.colab import files
files.download(output_filename)

print(f"DataFrame shape before dropping other country profiles: {df.shape}")

# Filter to keep only profiles from Bangladesh or India
df = df[df['country'].isin(['Bangladesh', 'India'])]

print(f"DataFrame shape after dropping other country profiles: {df.shape}")
print("Unique countries remaining in the DataFrame:")
for country in df['country'].unique():
    print(country)
display(df.head())